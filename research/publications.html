---
layout: page
title: "Publications"
description: ""
tagline: "last updated on April 16, 2014"
group: research
---
{% include JB/setup %}
<ul class="nav nav-tabs">
<li><a href="#All" data-toggle="tab">All (20)</a></li>
<li><a href="#Journalarticles" data-toggle="tab">Journal articles (1)</a></li>
<li><a href="#Bookchapters" data-toggle="tab">Book chapters (0)</a></li>
<li><a href="#Conferenceandworkshopproceedings" data-toggle="tab">Conference and workshop proceedings (19)</a></li>
</ul>
<div id="myTabContent" class="tab-content">
<div class="tab-pane fade in active" id="All">
<div class="accordion" id="accordionAll">
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14']);">
        Development of a Korean speech recognition system with little annontated data
        </a>
    </div>
    <div id="collapseLaurent14_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>SLTU 2014, Spoken Language Technologies for Under-resourced languages</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. Korean is an alpha-syllabary language spoken by about 78 million people worldwide.  As only a small amount of manually transcribed audio data were available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. The reported word and character error rates are estimates, as development corpus used in these experiments was also constructed from the untranscribed audio data, the web texts and automatic transcriptions. Several variants for unsupervised acoustic model training were compared to assess the influence of the vocabulary size (200k vs 2M), the type of language model (words vs characters), the acoustic unit (phonemes vs half-syllables), as well as incremental batch vs iterative decoding of the untranscribed audio corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14']);">.bib</a> [Laurent14] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14b']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseLaurent14b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bredin, H., Laurent, A., Sarkar, A., Le, V.-B., Barras, Claude, Rosset, Sophie
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ``who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification -- leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14b']);">.bib</a> [Laurent14b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14e_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14e']);">
        Boosting bonsai trees for efficient features combination : application to speaker role identification  (en attente d'acceptation / rejet)
        </a>
    </div>
    <div id="collapseLaurent14e_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Camelin, N., Raymond, C.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>In this article, we tackle the problem of speaker role detection from broadcast news shows. In the literature, many proposed solutions are based on the combination of various features coming from acoustic, lexical and semantic information with a machine learning algorithm. Many previous studies mention the use of boosting over decision stumps to combine efficiently these features. In this work, we propose a modification of this state-of-the-art machine learning algorithm changing the weak learner (decision stumps) by small decision trees, denoted bonsai trees. Experiments show that using bonsai trees as weak learners for the boosting algorithm largely improves both system error rate and learning time.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14e']);">.bib</a> [Laurent14e] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14d_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14d']);">
        Unsupervised training of the under-resourced Korean language (en attente d'acceptation / rejet)
        </a>
    </div>
    <div id="collapseLaurent14d_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Hartmann, W., Lamel, L.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. As only a small amount of manually transcribed audio data was available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. We assessed the effects of unsupervised training on several types of acoustic models. Initial results were reported on an unsupervised test corpus. Further experiments assessed transcription performance using a manually corrected version of this test corpus. While overall results improved, the improvements from higher-order language models disappeared and unsupervised training decreased. We investigate some possibilities for this unexpected result.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14d']);">.bib</a> [Laurent14d] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14c_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14c']);">
        Improving recognition of proper nouns in ASR through generating and filtering phonetic transcriptions
        </a>
    </div>
    <div id="collapseLaurent14c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Deléglise, P.
<p><em>In Computer Speech And Language</em></p>
<blockquote><p>Accurate phonetic transcription of proper nouns can be an important resource for commercial applications that embed speech technologies, such as audio indexing and vocal phone directory lookup. However, an accurate phonetic transcription is more difficult to obtain for proper nouns than for regular words. Indeed, phonetic transcription of a proper noun depends on both the origin of the speaker pronouncing it and the origin of the proper noun itself.This work proposes a method that allows the extraction of phonetic transcriptions of proper nouns using actual utterances of those proper nouns, thus yielding transcriptions based on practical use instead of mere pronunciation rules.The proposed method consists in a process that first extracts phonetic transcriptions, and then iteratively filters them. In order to initialize the process, an alignment dictionary is used to detect word boundaries. A rule-based grapheme-to-phoneme generator (LIA_PHON), a knowledge-based approach (JSM), and a Statistical Machine Translation based system were evaluated for this alignment.  As a result, compared to our reference dictionary (BDLEX supplemented by LIA_PHON for missing words) on the ESTER 1 French broadcast news corpus, we were able to significantly decrease the Word Error Rate (WER) on segments of speech with proper nouns, without negatively affecting the WER on the rest of the corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14c']);">.bib</a> [Laurent14c] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14c']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j5_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j5']);">
        Décodage hybride dans les SRAP pour l'indexation automatique de documents multimédia
        </a>
    </div>
    <div id="collapseLaurent14j5_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouaziz, M., Laurent, A., Estève, Y.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Certains Systèmes de Reconnaissance Automatique de la Parole (SRAP) atteignent des taux d'erreur de l'ordre de 10%. Toutefois, notamment dans le cadre de l'indexation automatique des documents multimédia sur le web, les SRAP se trouvent face à la problématique des mots hors-vocabulaire. En effet, les entités nommées en constituent une grande partie et sont remarquablement importantes pour les tâches d'indexation. Nous mettons en œuvre, dans ce travail, la solution du décodage hybride en utilisant les syllabes comme unités sous-lexicales. Cette méthode est intégrée au sein du SRAP LIUM'08 développé par le Laboratoire d'Informatique de l'Université du Maine. Avec une légère dégradation de la performance générale du système, environ 31% des noms de personne hors vocabulaire sont correctement reconnus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j5']);">.bib</a> [Laurent14j5] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j5.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j5']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j4_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j4']);">
        Traduction de la parole dans le projet RAPMAT
        </a>
    </div>
    <div id="collapseLaurent14j4_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bonneau-Maynard, H., Segal, N., Bilinski, E., Gauvain, J.-L., Gong, L., Lamel, L., Laurent, A., Yvon, F., Despres, J., Josse, Y., Le, V.-B.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Le projet RAPMAT vise à développer des systèmes de traduction de la parole en s’intéressant aux deux traitements constitutifs de la chaîne complète : la reconnaissance de la parole (RAP) et la traduction (TA). Dans la situation classique, les modèles statistiques utilisés par les deux systèmes sont estimés indépendemment, à partir de données de différentes natures (transcriptions manuelles de données de parole pour la RAP et corpus bilingues issus de données textuelles pour la TA). Nous proposons une approche semi-supervisée pour l'adaptation des modèles de traduction à la traduction de parole, dans laquelle les modèles de TA sont entraînés en intégrant des transcriptions manuelles et automatiques de la parole  traduites automatiquement. L'approche est expérimentée sur la direction de traduction français vers anglais. Un prototype de démonstration sur smartphones, incluant notamment la traduction de parole pour les paires de langues français/anglais et français/chinois a été développé pour permettre la collecte de données.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j4']);">.bib</a> [Laurent14j4] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j4.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j4']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j3_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j3']);">
        Développement d'un système de reconnaissance automatique de la parole en coréen avec peu de ressources annotées
        </a>
    </div>
    <div id="collapseLaurent14j3_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Ce papier décrit le développement d'un système de reconnaissance automatique de la parole pour le coréen. Le coréen est une langue alpha-syllabique, parlée par environ 78 millions de personnes dans le monde. Le développement de ce système a été mené en utilisant très peu de données annotées manuellement. Les modèles acoustiques ont été adaptés de manière non supervisée en utilisant des données provenant de différents sites d'actualités coréens. Le corpus de développement contient des transcriptions approximatives des documents audio : il s'agit d'un corpus transcrit automatiquement et aligné avec des données provenant des mêmes sites Internet. Nous comparons différentes approches dans ce travail, à savoir, des modèles de langue utilisant des unités différentes pour l'apprentissage non supervisé et pour le décodage (des caractères et des mots avec des vocabulaires de différentes tailles), l'utilisation de phonèmes et d'unités ``demi-syllabiques'' et deux approches différentes d'apprentissage non supervisé.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j3']);">.bib</a> [Laurent14j3] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j3.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j3']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j2_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j2']);">
        Analyse du corpus MATRICE : exploration et classification automatique d'archives audiovisuelles de 1930 à 2012
        </a>
    </div>
    <div id="collapseLaurent14j2_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Guinaudeau, C., Roy, A.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Cet article décrit les méthodes mises en place pour permettre l'analyse d'un corpus composé de documents audiovisuels diffusés au cours des 80 dernières années : le corpus MATRICE. Nous proposons une exploration des données permettant de mettre en évidence les différents thèmes et évènements abordés dans le corpus. Cette exploration est, dans un premier temps, effectuée sur des notices documentaires produites manuellement par les documentalistes de l'Institut National de l'Audiovisuel. Puis, nous montrons, grâce à une étude qualitative et une technique de clustering automatique, que les transcriptions automatiques permettent également d'effectuer une analyse du corpus faisant émerger des thèmes cohérents avec les données traitées.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j2']);">.bib</a> [Laurent14j2] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j2.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j2']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j1']);">
        Boosting de bonzaï pour la combinaison efficace de descripteurs : application à l'identification du rôle du locuteur
        </a>
    </div>
    <div id="collapseLaurent14j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Camelin, N., Raymond, C.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Dans ce travail, nous nous intéressons au problème de la détection du rôle du locuteur dans les émissions d'actualités radiotélévisées. Dans la littérature, les solutions proposées sont de combiner des indicateurs variés provenant de l'acoustique, de la transcription et/ou de son analyse par des méthodes d'apprentissage automatique. De nombreuses études font ressortir l'algorithme de boosting sur des règles de décision simples comme l'un des plus efficaces à combiner ces différents descripteurs. Nous proposons ici une modification de cet algorithme état-de-l'art en remplaçant ces règles de décision simples par des mini arbres de décision que nous appelons bonzaïs. Les expériences comparatives menées sur le corpus EPAC montrent que cette modification améliore largement les performances du système tout en réduisant le temps d'apprentissage de manière conséquente.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j1']);">.bib</a> [Laurent14j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent12_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12']);">
        Combining transcription-based and acoustic-based speaker identifications for broadcast news
        </a>
    </div>
    <div id="collapseLaurent12_All" class="accordion-body collapse">
        <div class="accordion-inner">
        El-Khoury, E., Laurent, A., Meignier, S., Petitrenaud, S.
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12']);">.bib</a> [Laurent12] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent12j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12j1']);">
        Combinaison d'approches pour la reconnaissance du rôle des locuteurs
        </a>
    </div>
    <div id="collapseLaurent12j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Dufour, R., Laurent, A., Estève, Y.
<p><em>JEP 2012, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12j1']);">.bib</a> [Laurent12j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent11_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent11']);">
        Computer-assisted transcription of speech based on confusion network reordering
        </a>
    </div>
    <div id="collapseLaurent11_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>ICASSP 2011, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent11']);">.bib</a> [Laurent11] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent11.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent11']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseEsteve10_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Esteve10']);">
        Some recent research work at LIUM based on the use of CMU Sphinx
        </a>
    </div>
    <div id="collapseEsteve10_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Estève, Y., Deléglise, P., Meignier, S., Petitrenaud, S., Schwenk, H., Barrault, L., Bougares, F., Dufour, R., Jousse, V., Laurent, A., Rousseau, A.
<p><em>Workshop CMU SPU</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Esteve10']);">.bib</a> [Esteve10] | <i class="icon-book"></i> <a href="/download/pdfs/Esteve10.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Esteve10']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent10j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10j1']);">
        Réordonnancement automatique d'hypothèses pour l'assistance à la transcription de la parole
        </a>
    </div>
    <div id="collapseLaurent10j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Meignier, S., Deléglise, P.
<p><em>JEP 2010, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10j1']);">.bib</a> [Laurent10j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent10-b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10-b']);">
        Acoustics-Based Phonetic Transcription Method for Proper Nouns
        </a>
    </div>
    <div id="collapseLaurent10-b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>Interspeech 2010, 11th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10-b']);">.bib</a> [Laurent10-b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10-b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10-b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent09b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09b']);">
        Grapheme to phoneme conversion using an SMT system
        </a>
    </div>
    <div id="collapseLaurent09b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Deléglise, P., Meignier, S.
<p><em>Interspeech 2009, 10th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09b']);">.bib</a> [Laurent09b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent09_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09']);">
        Iterative filtrering of phonetic transcriptions of proper nouns
        </a>
    </div>
    <div id="collapseLaurent09_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>ICASSP 2009, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09']);">.bib</a> [Laurent09] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent08b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08b']);">
        Combinaison de systèmes pour la phonétisation automatique de noms propres
        </a>
    </div>
    <div id="collapseLaurent08b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., and Meignier, S., Estève, Y., Deléglise, P.
<p><em>JEP 2008, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08b']);">.bib</a> [Laurent08b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent08_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08']);">
        Combined systems for automatic phonetic transcription of proper nouns
        </a>
    </div>
    <div id="collapseLaurent08_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>LREC 2008, Language Resources and Evaluation Conference</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08']);">.bib</a> [Laurent08] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Journalarticles">
<div class="accordion" id="accordionJournalarticles">
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseLaurent14c_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14c']);">
        Improving recognition of proper nouns in ASR through generating and filtering phonetic transcriptions
        </a>
    </div>
    <div id="collapseLaurent14c_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Deléglise, P.
<p><em>In Computer Speech And Language</em></p>
<blockquote><p>Accurate phonetic transcription of proper nouns can be an important resource for commercial applications that embed speech technologies, such as audio indexing and vocal phone directory lookup. However, an accurate phonetic transcription is more difficult to obtain for proper nouns than for regular words. Indeed, phonetic transcription of a proper noun depends on both the origin of the speaker pronouncing it and the origin of the proper noun itself.This work proposes a method that allows the extraction of phonetic transcriptions of proper nouns using actual utterances of those proper nouns, thus yielding transcriptions based on practical use instead of mere pronunciation rules.The proposed method consists in a process that first extracts phonetic transcriptions, and then iteratively filters them. In order to initialize the process, an alignment dictionary is used to detect word boundaries. A rule-based grapheme-to-phoneme generator (LIA_PHON), a knowledge-based approach (JSM), and a Statistical Machine Translation based system were evaluated for this alignment.  As a result, compared to our reference dictionary (BDLEX supplemented by LIA_PHON for missing words) on the ESTER 1 French broadcast news corpus, we were able to significantly decrease the Word Error Rate (WER) on segments of speech with proper nouns, without negatively affecting the WER on the rest of the corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14c']);">.bib</a> [Laurent14c] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14c']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Bookchapters">
<div class="accordion" id="accordionBookchapters">
</div>
</div>
<div class="tab-pane fade in" id="Conferenceandworkshopproceedings">
<div class="accordion" id="accordionConferenceandworkshopproceedings">
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14']);">
        Development of a Korean speech recognition system with little annontated data
        </a>
    </div>
    <div id="collapseLaurent14_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>SLTU 2014, Spoken Language Technologies for Under-resourced languages</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. Korean is an alpha-syllabary language spoken by about 78 million people worldwide.  As only a small amount of manually transcribed audio data were available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. The reported word and character error rates are estimates, as development corpus used in these experiments was also constructed from the untranscribed audio data, the web texts and automatic transcriptions. Several variants for unsupervised acoustic model training were compared to assess the influence of the vocabulary size (200k vs 2M), the type of language model (words vs characters), the acoustic unit (phonemes vs half-syllables), as well as incremental batch vs iterative decoding of the untranscribed audio corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14']);">.bib</a> [Laurent14] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14b']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseLaurent14b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bredin, H., Laurent, A., Sarkar, A., Le, V.-B., Barras, Claude, Rosset, Sophie
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ``who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification -- leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14b']);">.bib</a> [Laurent14b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14e_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14e']);">
        Boosting bonsai trees for efficient features combination : application to speaker role identification  (en attente d'acceptation / rejet)
        </a>
    </div>
    <div id="collapseLaurent14e_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Camelin, N., Raymond, C.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>In this article, we tackle the problem of speaker role detection from broadcast news shows. In the literature, many proposed solutions are based on the combination of various features coming from acoustic, lexical and semantic information with a machine learning algorithm. Many previous studies mention the use of boosting over decision stumps to combine efficiently these features. In this work, we propose a modification of this state-of-the-art machine learning algorithm changing the weak learner (decision stumps) by small decision trees, denoted bonsai trees. Experiments show that using bonsai trees as weak learners for the boosting algorithm largely improves both system error rate and learning time.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14e']);">.bib</a> [Laurent14e] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14d_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14d']);">
        Unsupervised training of the under-resourced Korean language (en attente d'acceptation / rejet)
        </a>
    </div>
    <div id="collapseLaurent14d_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Hartmann, W., Lamel, L.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. As only a small amount of manually transcribed audio data was available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. We assessed the effects of unsupervised training on several types of acoustic models. Initial results were reported on an unsupervised test corpus. Further experiments assessed transcription performance using a manually corrected version of this test corpus. While overall results improved, the improvements from higher-order language models disappeared and unsupervised training decreased. We investigate some possibilities for this unexpected result.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14d']);">.bib</a> [Laurent14d] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j5_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j5']);">
        Décodage hybride dans les SRAP pour l'indexation automatique de documents multimédia
        </a>
    </div>
    <div id="collapseLaurent14j5_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouaziz, M., Laurent, A., Estève, Y.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Certains Systèmes de Reconnaissance Automatique de la Parole (SRAP) atteignent des taux d'erreur de l'ordre de 10%. Toutefois, notamment dans le cadre de l'indexation automatique des documents multimédia sur le web, les SRAP se trouvent face à la problématique des mots hors-vocabulaire. En effet, les entités nommées en constituent une grande partie et sont remarquablement importantes pour les tâches d'indexation. Nous mettons en œuvre, dans ce travail, la solution du décodage hybride en utilisant les syllabes comme unités sous-lexicales. Cette méthode est intégrée au sein du SRAP LIUM'08 développé par le Laboratoire d'Informatique de l'Université du Maine. Avec une légère dégradation de la performance générale du système, environ 31% des noms de personne hors vocabulaire sont correctement reconnus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j5']);">.bib</a> [Laurent14j5] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j5.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j5']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j4_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j4']);">
        Traduction de la parole dans le projet RAPMAT
        </a>
    </div>
    <div id="collapseLaurent14j4_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bonneau-Maynard, H., Segal, N., Bilinski, E., Gauvain, J.-L., Gong, L., Lamel, L., Laurent, A., Yvon, F., Despres, J., Josse, Y., Le, V.-B.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Le projet RAPMAT vise à développer des systèmes de traduction de la parole en s’intéressant aux deux traitements constitutifs de la chaîne complète : la reconnaissance de la parole (RAP) et la traduction (TA). Dans la situation classique, les modèles statistiques utilisés par les deux systèmes sont estimés indépendemment, à partir de données de différentes natures (transcriptions manuelles de données de parole pour la RAP et corpus bilingues issus de données textuelles pour la TA). Nous proposons une approche semi-supervisée pour l'adaptation des modèles de traduction à la traduction de parole, dans laquelle les modèles de TA sont entraînés en intégrant des transcriptions manuelles et automatiques de la parole  traduites automatiquement. L'approche est expérimentée sur la direction de traduction français vers anglais. Un prototype de démonstration sur smartphones, incluant notamment la traduction de parole pour les paires de langues français/anglais et français/chinois a été développé pour permettre la collecte de données.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j4']);">.bib</a> [Laurent14j4] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j4.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j4']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j3_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j3']);">
        Développement d'un système de reconnaissance automatique de la parole en coréen avec peu de ressources annotées
        </a>
    </div>
    <div id="collapseLaurent14j3_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Ce papier décrit le développement d'un système de reconnaissance automatique de la parole pour le coréen. Le coréen est une langue alpha-syllabique, parlée par environ 78 millions de personnes dans le monde. Le développement de ce système a été mené en utilisant très peu de données annotées manuellement. Les modèles acoustiques ont été adaptés de manière non supervisée en utilisant des données provenant de différents sites d'actualités coréens. Le corpus de développement contient des transcriptions approximatives des documents audio : il s'agit d'un corpus transcrit automatiquement et aligné avec des données provenant des mêmes sites Internet. Nous comparons différentes approches dans ce travail, à savoir, des modèles de langue utilisant des unités différentes pour l'apprentissage non supervisé et pour le décodage (des caractères et des mots avec des vocabulaires de différentes tailles), l'utilisation de phonèmes et d'unités ``demi-syllabiques'' et deux approches différentes d'apprentissage non supervisé.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j3']);">.bib</a> [Laurent14j3] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j3.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j3']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j2_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j2']);">
        Analyse du corpus MATRICE : exploration et classification automatique d'archives audiovisuelles de 1930 à 2012
        </a>
    </div>
    <div id="collapseLaurent14j2_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Guinaudeau, C., Roy, A.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Cet article décrit les méthodes mises en place pour permettre l'analyse d'un corpus composé de documents audiovisuels diffusés au cours des 80 dernières années : le corpus MATRICE. Nous proposons une exploration des données permettant de mettre en évidence les différents thèmes et évènements abordés dans le corpus. Cette exploration est, dans un premier temps, effectuée sur des notices documentaires produites manuellement par les documentalistes de l'Institut National de l'Audiovisuel. Puis, nous montrons, grâce à une étude qualitative et une technique de clustering automatique, que les transcriptions automatiques permettent également d'effectuer une analyse du corpus faisant émerger des thèmes cohérents avec les données traitées.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j2']);">.bib</a> [Laurent14j2] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j2.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j2']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j1']);">
        Boosting de bonzaï pour la combinaison efficace de descripteurs : application à l'identification du rôle du locuteur
        </a>
    </div>
    <div id="collapseLaurent14j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Camelin, N., Raymond, C.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Dans ce travail, nous nous intéressons au problème de la détection du rôle du locuteur dans les émissions d'actualités radiotélévisées. Dans la littérature, les solutions proposées sont de combiner des indicateurs variés provenant de l'acoustique, de la transcription et/ou de son analyse par des méthodes d'apprentissage automatique. De nombreuses études font ressortir l'algorithme de boosting sur des règles de décision simples comme l'un des plus efficaces à combiner ces différents descripteurs. Nous proposons ici une modification de cet algorithme état-de-l'art en remplaçant ces règles de décision simples par des mini arbres de décision que nous appelons bonzaïs. Les expériences comparatives menées sur le corpus EPAC montrent que cette modification améliore largement les performances du système tout en réduisant le temps d'apprentissage de manière conséquente.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j1']);">.bib</a> [Laurent14j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent12_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12']);">
        Combining transcription-based and acoustic-based speaker identifications for broadcast news
        </a>
    </div>
    <div id="collapseLaurent12_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        El-Khoury, E., Laurent, A., Meignier, S., Petitrenaud, S.
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12']);">.bib</a> [Laurent12] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent12j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12j1']);">
        Combinaison d'approches pour la reconnaissance du rôle des locuteurs
        </a>
    </div>
    <div id="collapseLaurent12j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Dufour, R., Laurent, A., Estève, Y.
<p><em>JEP 2012, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12j1']);">.bib</a> [Laurent12j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent11_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent11']);">
        Computer-assisted transcription of speech based on confusion network reordering
        </a>
    </div>
    <div id="collapseLaurent11_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>ICASSP 2011, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent11']);">.bib</a> [Laurent11] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent11.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent11']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseEsteve10_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Esteve10']);">
        Some recent research work at LIUM based on the use of CMU Sphinx
        </a>
    </div>
    <div id="collapseEsteve10_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Estève, Y., Deléglise, P., Meignier, S., Petitrenaud, S., Schwenk, H., Barrault, L., Bougares, F., Dufour, R., Jousse, V., Laurent, A., Rousseau, A.
<p><em>Workshop CMU SPU</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Esteve10']);">.bib</a> [Esteve10] | <i class="icon-book"></i> <a href="/download/pdfs/Esteve10.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Esteve10']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent10j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10j1']);">
        Réordonnancement automatique d'hypothèses pour l'assistance à la transcription de la parole
        </a>
    </div>
    <div id="collapseLaurent10j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Meignier, S., Deléglise, P.
<p><em>JEP 2010, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10j1']);">.bib</a> [Laurent10j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent10-b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10-b']);">
        Acoustics-Based Phonetic Transcription Method for Proper Nouns
        </a>
    </div>
    <div id="collapseLaurent10-b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>Interspeech 2010, 11th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10-b']);">.bib</a> [Laurent10-b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10-b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10-b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent09b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09b']);">
        Grapheme to phoneme conversion using an SMT system
        </a>
    </div>
    <div id="collapseLaurent09b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Deléglise, P., Meignier, S.
<p><em>Interspeech 2009, 10th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09b']);">.bib</a> [Laurent09b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent09_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09']);">
        Iterative filtrering of phonetic transcriptions of proper nouns
        </a>
    </div>
    <div id="collapseLaurent09_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>ICASSP 2009, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09']);">.bib</a> [Laurent09] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent08b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08b']);">
        Combinaison de systèmes pour la phonétisation automatique de noms propres
        </a>
    </div>
    <div id="collapseLaurent08b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., and Meignier, S., Estève, Y., Deléglise, P.
<p><em>JEP 2008, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08b']);">.bib</a> [Laurent08b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent08_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08']);">
        Combined systems for automatic phonetic transcription of proper nouns
        </a>
    </div>
    <div id="collapseLaurent08_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>LREC 2008, Language Resources and Evaluation Conference</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08']);">.bib</a> [Laurent08] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-51856344-1', 'antoine-laurent.fr');
  ga('send', 'pageview');

</script>
