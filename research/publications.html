---
layout: page
title: "Publications"
description: ""
tagline: "last updated on March 31, 2021"
group: research
---
{% include JB/setup %}
<ul class="nav nav-tabs">
<li><a href="#All" data-toggle="tab">All (51)</a></li>
<li><a href="#Journalarticles" data-toggle="tab">Journal articles (4)</a></li>
<li><a href="#Bookchapters" data-toggle="tab">Book chapters (0)</a></li>
<li><a href="#Conferenceandworkshopproceedings" data-toggle="tab">Conference and workshop proceedings (47)</a></li>
</ul>
<div id="myTabContent" class="tab-content">
<div class="tab-pane fade in active" id="All">
<div class="accordion" id="accordionAll">
<h3>2021</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsepelloin21_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'pelloin21']);">
        End2End Acoustic to Semantic Transduction
        </a>
    </div>
    <div id="collapsepelloin21_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Valentin Pelloin, Nathalie Camelin, Antoine Laurent, Renato de Mori, Antoine Caubrière, Yannick Estève, Sylvain Meignier
<p><em>ICASSP 2021</em></p>
<blockquote><p>In this paper, we propose a novel end-to-end sequence-to-sequence spoken language understanding model using an attention mechanism. It reliably selects contextual acoustic features in order to hypothesize semantic contents. An initial architecture capable of extracting all pronounced words and concepts from acoustic spans is designed and tested. With a shallow fusion language model, this system reaches a 13.6 concept error rate (CER) and an 18.5 concept value error rate (CVER) on the French MEDIA corpus, achieving an absolute 2.8 points reduction compared to the state-of-the-art. Then, an original model is proposed for hypothesizing concepts and their values. This transduction reaches a 15.4 CER and a 21.6 CVER without any new type of context.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'pelloin21']);">.bib</a> [pelloin21] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecarrive21_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'carrive21']);">
        Transdisciplinary Analysis of a Corpus of French Newsreels: The ANTRACT Project
        </a>
    </div>
    <div id="collapsecarrive21_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Jean Carrive, Abdelkrim Beloued, Pascale Goetschel, Serge Heiden, Antoine Laurent, Pasquale Lisena, Franck Mazuet, Sylvain Meignier, Bénédicte Pincemin, Géraldine Poels, Raphaël Troncy
<p><em>Digital Humanities Quarterly</em></p>
<blockquote><p>The ANTRACT project is a cross-disciplinary apparatus dedicated to the analysis of the French newsreel company Les Actualités Françaises (1945-1969) and its film productions. Founded during the liberation of France, this state-owned company filmed more than 20,000 news reports shown in French cinemas and throughout the world over its 24 years of activity. The project brings together research organizations with a dual historical and technological perspective. ANTRACT’s goal is to study the production process, the film content, the way historical events are represented and the audience reception of Les Actualités Françaises newsreels using innovative AI-based data processing tools developed by partners specialized in image, audio, and text analysis. This article focuses on the data processing apparatus and tools of the project. Automatic content analysis is used to select data, to segment video units and typescript images, and to align them with their archival description. Automatic speech recognition provides a textual representation and natural language processing can extract named entities from the voice-over recording; automatic visual analysis is applied to detect and recognize faces of well-known characters in videos. These multifaceted data can then be queried and explored with the TXM text-mining platform. The results of these automatic analysis processes are feeding the Okapi platform, a client-server software that integrates documentation, information retrieval, and hypermedia capabilities within a single environment based on the Semantic Web standards. The complete corpus of Les Actualités Françaises, enriched with data and metadata, will be made available to the scientific community by the end of the project.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'carrive21']);">.bib</a> [carrive21] | <i class="icon-book"></i> <a href="/download/pdfs/carrive21.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'carrive21']);">.pdf</a>        </div>
    </div>
</div>
<h3>2020</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsemontresor20_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'montresor20']);">
        Deep learning-based speckle decorrelation denoising for wide-field optical metrology
        </a>
    </div>
    <div id="collapsemontresor20_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Silvio Montrésor, Marie Tahon, Antoine Laurent, Picart Pascal
<p><em>SPIE Photonics Europe International Symposium</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'montresor20']);">.bib</a> [montresor20] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsemdhaffar2020_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'mdhaffar2020']);">
        A Multimodal Educational Corpus of Oral Courses: Annotation, Analysis and Case Study
        </a>
    </div>
    <div id="collapsemdhaffar2020_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima mdhaffar, Yannick Estève, Antoine Laurent, Nicolas Hernandez, Richard Dufour, Delphine Charlet, Geraldine Damnati, Solen Quiniou, Nathalie Camelin
<p><em>LREC 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'mdhaffar2020']);">.bib</a> [mdhaffar2020] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecaubriere2020b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020b']);">
        ERROR ANALYSIS APPLIED TO END-TO-END SPOKEN LANGUAGE UNDERSTANDING
        </a>
    </div>
    <div id="collapsecaubriere2020b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sahar Ghannay, Natalia Tomashenko, Renato De Mori, Antoine Laurent, Emmanuel Morin, Yannick Estève
<p><em>ICASSP 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020b']);">.bib</a> [caubriere2020b] | <i class="icon-book"></i> <a href="/download/pdfs/caubriere2020b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'caubriere2020b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecaubriere2020_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020']);">
        Where are we in Named Entity Recognition from Speech?
        </a>
    </div>
    <div id="collapsecaubriere2020_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sophie Rosset, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>LREC 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020']);">.bib</a> [caubriere2020] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecaubriere2020jep_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020jep']);">
        Où en sommes-nous dans la reconnaissance des entités nommées structurées à partir de la parole ?
        </a>
    </div>
    <div id="collapsecaubriere2020jep_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sophie Rosset, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>JEP 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020jep']);">.bib</a> [caubriere2020jep] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecaubriere2020int_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020int']);">
        Confidence measure for speech-to-concept end-to-end spoken language understanding
        </a>
    </div>
    <div id="collapsecaubriere2020int_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>Interspeech 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020int']);">.bib</a> [caubriere2020int] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsedolfing20_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'dolfing20']);">
        The "ScribbleLens" Dutch historical handwriting corpus
        </a>
    </div>
    <div id="collapsedolfing20_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hans Dolfing, Jérome Bellegarda, Jan Chorowski, Ricard Marxer, Antoine Laurent
<p><em>ICFHR 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'dolfing20']);">.bib</a> [dolfing20] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsemontresor20b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'montresor20b']);">
        Computational de-noising based on deep learning for phase data in digital holographic interferometry
        </a>
    </div>
    <div id="collapsemontresor20b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Silvio Montrésor, Marie Tahon, Antoine Laurent, Pascal Picart
<p><em>APL Photonics AIP Publishing LLC</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'montresor20b']);">.bib</a> [montresor20b] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapselancucki20_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'lancucki20']);">
        Robust Training of Vector Quantized Bottleneck Models
        </a>
    </div>
    <div id="collapselancucki20_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Adrian Łancucki, Jan Chorowski, Guillaume Sanchez, Ricard Marxer, Nanxin Chen, Hans J G A Dolfing, Sameer Khurana, Tanel Alumäe, Antoine Laurent
<p><em>IJCNN 2020</em></p>
<blockquote><p>In this paper we demonstrate methods for reliable and efficient training of discrete representation using Vector-Quantized Variational Auto-Encoder models (VQ-VAEs). Discrete latent variable models have been shown to learn nontrivial representations of speech, applicable to unsupervised voice conversion and reaching state-of-the-art performance on unit discovery tasks. For unsupervised representation learning, they became viable alternatives to continuous latent variable models such as the Variational Auto-Encoder (VAE). However, training deep discrete variable models is challenging, due to the inherent non-differentiability of the discretization operation. In this paper we focus on VQ-VAE, a state-of-the-art discrete bottleneck model shown to perform on par with its continuous counterparts. It quantizes encoder outputs with on-line k-means clustering. We show that the codebook learning can suffer from poor initialization and non-stationarity of clustered encoder outputs. We demonstrate that these can be successfully overcome by increasing the learning rate for the codebook and periodic date-dependent codeword re-initialization. As a result, we achieve more robust training across different tasks, and significantly increase the usage of latent codewords even for large codebooks. This has practical benefit, for instance, in unsupervised representation learning, where large codebooks may lead to disentanglement of latent representations.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'lancucki20']);">.bib</a> [lancucki20] | <i class="icon-book"></i> <a href="/download/pdfs/lancucki20.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'lancucki20']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsekhurana20b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'khurana20b']);">
        CSTNet: Contrastive Speech Translation Network for Self-Supervised Speech Representation Learning
        </a>
    </div>
    <div id="collapsekhurana20b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Sameer Khurana, Antoine Laurent, James Glass
<p><em>Arxiv</em></p>
<blockquote><p>More than half of the 7,000 languages in the world are in imminent danger of going extinct. Traditional methods of documenting language proceed by collecting audio data followed by manual annotation by trained linguists at different levels of granularity. This time consuming and painstaking process could benefit from machine learning. Many endangered languages do not have any orthographic form but usually have speakers that are bi-lingual and trained in a high resource language. It is relatively easy to obtain textual translations corresponding to speech. In this work, we provide a multimodal machine learning framework for speech representation learning by exploiting the correlations between the two modalities namely speech and its corresponding text translation. Here, we construct a convolutional neural network audio encoder capable of extracting linguistic representations from speech. The audio encoder is trained to perform a speech-translation retrieval task in a contrastive learning framework. By evaluating the learned representations on a phone recognition task, we demonstrate that linguistic representations emerge in the audio encoder's internal representations as a by-product of learning to perform the retrieval task.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'khurana20b']);">.bib</a> [khurana20b] | <i class="icon-book"></i> <a href="/download/pdfs/khurana20b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'khurana20b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsekhurana20_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'khurana20']);">
        A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning
        </a>
    </div>
    <div id="collapsekhurana20_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Sameer Khurana, Antoine Laurent, Wei-Ning Hsu, Jan Chorowski, Adrian Lancucki, Ricard Marxer, James Glass
<p><em>Interspeech 2020</em></p>
<blockquote><p>Probabilistic Latent Variable Models (LVMs) provide an alternative to self-supervised learning approaches for linguistic representation learning from speech. LVMs admit an intuitive probabilistic interpretation where the latent structure shapes the information extracted from the signal. Even though LVMs have recently seen a renewed interest due to the introduction of Variational Autoencoders (VAEs), their use for speech representation learning remains largely unexplored. In this work, we propose Convolutional Deep Markov Model (ConvDMM), a Gaussian state-space model with non-linear emission and transition functions modelled by deep neural networks. This unsupervised model is trained using black box variational inference. A deep convolutional neural network is used as an inference network for structured variational approximation. When trained on a large scale speech dataset (LibriSpeech), ConvDMM produces features that significantly outperform multiple self-supervised feature extracting methods on linear phone classification and recognition on the Wall Street Journal dataset. Furthermore, we found that ConvDMM complements self-supervised methods like Wav2Vec and PASE, improving on the results achieved with any of the methods alone. Lastly, we find that ConvDMM features enable learning better phone recognizers than any other features in an extreme low-resource regime with few labeled training examples.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'khurana20']);">.bib</a> [khurana20] | <i class="icon-book"></i> <a href="/download/pdfs/khurana20.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'khurana20']);">.pdf</a>        </div>
    </div>
</div>
<h3>2019</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMdhaffar19b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar19b']);">
        Apport de l’adaptation automatique des modèles de langage pour la reconnaissance de la parole : évaluation qualitative extrinsèque dans un contexte de traitement de cours magistraux.
        </a>
    </div>
    <div id="collapseMdhaffar19b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima Mdhaffar, Yannick Estève, Nicolas Hernandez, Antoine Laurent, Solen Quiniou
<p><em>26e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2019)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar19b']);">.bib</a> [Mdhaffar19b] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsecaubriere2019curriculum_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2019curriculum']);">
        Curriculum d'apprentissage: reconnaissance d'entités nommées pour l'extraction de concepts sémantiques
        </a>
    </div>
    <div id="collapsecaubriere2019curriculum_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Caubrière, Antoine, Tomashenko, Natalia, Estève, Yannick, Laurent, Antoine, Morin, Emmanuel
<p><em>26e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2019)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2019curriculum']);">.bib</a> [caubriere2019curriculum] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseCaubriere2019_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Caubriere2019']);">
        Curriculum-based transfer learning for an effective end-to-end spoken language understanding and domain portability
        </a>
    </div>
    <div id="collapseCaubriere2019_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Natalia Tomashenko, Antoine LAURENT, Emmanuel Morin, Nathalie Camelin, Yannick Estève
<p><em>Interspeech 2019, Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Caubriere2019']);">.bib</a> [Caubriere2019] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMdhaffar2019_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar2019']);">
        Qualitative evaluation of ASR adaptation in a lecture context: Application to the PASTEL corpus
        </a>
    </div>
    <div id="collapseMdhaffar2019_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima mdhaffar, Yannick Estève, Nicolas Hernandez, Antoine LAURENT, Solen Quiniou
<p><em>Interspeech 2019, Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar2019']);">.bib</a> [Mdhaffar2019] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsetomashenko2019recent_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'tomashenko2019recent']);">
        Recent Advances in End-to-End Spoken Language Understanding
        </a>
    </div>
    <div id="collapsetomashenko2019recent_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Tomashenko, Natalia, Caubrière, Antoine, Estève, Yannick, Laurent, Antoine, Morin, Emmanuel
<p><em>International Conference on Statistical Language and Speech Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'tomashenko2019recent']);">.bib</a> [tomashenko2019recent] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsechorowski19_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'chorowski19']);">
        Unsupervised Neural Segmentation and Clustering for Unit Discovery in Sequential Data
        </a>
    </div>
    <div id="collapsechorowski19_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Jan Chorowski, Nanxin Chen, Ricard Marxer, Hans J G A Dolfing, Adrian Ła\'ncucki, Guillaume Sanchez, Tanel Alum\"ae, Antoine Laurent
<p><em>NeurIPS 2019 workshop - Perception as generative reasoning - Structure, Causality, Probability</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'chorowski19']);">.bib</a> [chorowski19] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsegagnepain19_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'gagnepain19']);">
        Collective memory shapes the organization of individual memories in the medial prefrontal cortex
        </a>
    </div>
    <div id="collapsegagnepain19_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierre Gagnepain, Thomas Vallée, Serge Heiden, Matthieu Decorde, Jean-Luc Gauvain, Antoine Laurent, Carine Klein-Peschanski, Fausto Viader, Denis Peschanski, Francis Eustache
<p><em>Nature Human Behaviour</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'gagnepain19']);">.bib</a> [gagnepain19] | <i class="icon-book"></i> <a href="/download/pdfs/gagnepain19.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'gagnepain19']);">.pdf</a>        </div>
    </div>
</div>
<h3>2018</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMdhaffar18b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar18b']);">
        Le corpus PASTEL pour le traitement automatique de cours magistraux.
        </a>
    </div>
    <div id="collapseMdhaffar18b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Mdhaffar, A. Laurent, Y. Estève
<p><em>25e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2018)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar18b']);">.bib</a> [Mdhaffar18b] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMdhaffar2018_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar2018']);">
        Etude de performance des réseaux neuronaux récurrents dans le cadre de la campagne d'évaluation Multi-Genre Broadcast challenge 3 (MGB3)
        </a>
    </div>
    <div id="collapseMdhaffar2018_All" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Mdhaffar, A. Laurent, Y. Estève
<p><em>XXXIIe Journees d'Etudes sur la Parole (JEP 2018)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar2018']);">.bib</a> [Mdhaffar2018] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGhannay2018_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ghannay2018']);">
        End-to-end named entity and semantic concept extraction from speech
        </a>
    </div>
    <div id="collapseGhannay2018_All" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Gannay, A. Caubriere, Y. Estève, N. Camelin, E. Simmonet, A. Laurent
<p><em>IEEE Spoken Language Technology Workshop</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ghannay2018']);">.bib</a> [Ghannay2018] |         </div>
    </div>
</div>
<h3>2017</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseHuang17_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Huang17']);">
        AN INVESTIGATION INTO LANGUAGE MODEL DATA AUGMENTATION FOR LOW-RESOURCED STT AND KWS
        </a>
    </div>
    <div id="collapseHuang17_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Guangpu Huang, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain, Antoine Laurent, Rasa Lileikyte, Abdel Massouadi
<p><em>ICASSP 2017, The 42st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>This paper reports on investigations of using two tecnniques for language model text data augmentation for low-resourced automatic speech recognition and keyword search. Low-resourced languages are characterized by limited training materials, which typically results in high out-of-vocabulary (OOV) rates and poor language model estimates. One technique makes use of recurrent neural networks (RNNs) using word or subword units. Word-based RNNs keep the same system vocabulary, so they cannot reduce the OOV, whereas subword units can reduce the OOV but generate many false combinations. A complementary technique is based on automatic machine translation, which requires parallel texts and is able to add words to the vocabulary. These methods were accessed on 10 languages in the context of the Babel program and NIST OpenKWS evaluation. Although improvements vary across languages with both methods, small gains were generally observed in terms of word error rate reduction and improved keyword search performance.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Huang17']);">.bib</a> [Huang17] | <i class="icon-book"></i> <a href="/download/pdfs/Huang17.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Huang17']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLileikyte17_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Lileikyte17']);">
        EFFECTIVE KEYWORD SEARCH FOR LOW-RESOURCED CONVERSATIONAL SPEECH
        </a>
    </div>
    <div id="collapseLileikyte17_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Rasa Lileikyte, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain, Antoine Laurent, Guangpu Huang
<p><em>ICASSP 2017, The 42st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>In this paper we aim to enhance keyword search for conversational telephone speech under low-resourced conditions. Two techniques to improve the detection of out-of-vocabulary keywords are assessed in this study: using extra text resources to augment the lexicon and language model, and via subword units for keyword search. Two approaches for data augmentation are explored to extend the limited amount of transcribed conversational speech: using conversational-like Web data and texts generated by recurrent neural networks. Contrastive comparisons of subword-based systems are performed to evaluate the benefits of multiple subword decodings and single decoding. Keyword search results are reported for all the techniques, but only some improve performance. Results are reported for the Mongolian and Igbo languages using data from the 2016 Babel program.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Lileikyte17']);">.bib</a> [Lileikyte17] | <i class="icon-book"></i> <a href="/download/pdfs/Lileikyte17.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Lileikyte17']);">.pdf</a>        </div>
    </div>
</div>
<h3>2016</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGelly16_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gelly16']);">
        Language Recognition for Dialects and Closely Related Languages
        </a>
    </div>
    <div id="collapseGelly16_All" class="accordion-body collapse">
        <div class="accordion-inner">
        G. Gelly, J.L. Gauvain, L. Lamel, A. Laurent, V.B. Le, A. Messaoudi
<p><em>Odyssey 2016</em></p>
<blockquote><p>This paper describes our development work to design a language recognition system that can discriminate closely related languages and dialects of the same language. The work was a joint effort by LIMSI and Vocapia Research in preparation for the NIST 2015 Language Recognition Evaluation (LRE). The language recognition system results from a fusion of four core classifiers: a phonotactic component using DNN acoustic models, two purely acoustic components using a RNN model and and i-vector model, and a lexical component. Each component generates language posterior probabilities optimized to maximize the LID NCE, making their combination simple and robust. The motivation for using multiple components representing different speech knowledge is that some dialect distinctions may not be manifest at the acoustic level. We report experiments on the NIST LRE15 data and provide an analysis of the results and some post-evaluation contrasts.  The 2015 LRE task focused on the identification of 20 languages clustered in 6 groups (Arabic, Chinese, English, French, Slavic and Iberic) of similar languages. Results are reported using the NIST Cavg metric which served as the primary metric for the OpenLRE15 evaluation. Results are also reported for the EER and the LER.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gelly16']);">.bib</a> [Gelly16] | <i class="icon-book"></i> <a href="/download/pdfs/Gelly16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gelly16']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent16_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent16']);">
        INVESTIGATING TECHNIQUES FOR LOW RESOURCE CONVERSATIONAL SPEECH RECOGNITION
        </a>
    </div>
    <div id="collapseLaurent16_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Laurent, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain
<p><em>ICASSP 2016, The 41st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>In this paper we investigate various techniques in order to build effective speech to text (STT) and keyword search (KWS) systems for low resource conversational speech. Subword decoding and graphemic mappings were assessed in order to detect out-of-vocabulary keywords. To deal with the limited amount of transcribed data, semi-supervised training and data selection methods were investigated. Robust acoustic features produced via data augmentation were evaluated for acoustic modeling. For language modeling, automatically retrieved conversational-like Webdata was used, as well as neural network based models. We report STT improvements with all the techniques, but interestingly only some improve KWS performance. Results are reported for the Swahili language in the context of the 2015 OpenKWS Evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent16']);">.bib</a> [Laurent16] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent16']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGorin16_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gorin16']);">
        Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions
        </a>
    </div>
    <div id="collapseGorin16_All" class="accordion-body collapse">
        <div class="accordion-inner">
        A. Gorin, R. Lileikyte, G. Huang, L. Lamel, J.L. Gauvain, A. Laurent
<p><em>Interspeech 2016, Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This research extends our earlier work on using machine translation (MT) and word-based recurrent neural networks to augment language model training data for keyword search in conversational Cantonese speech. MT-based data augmentation is applied to two language pairs: English-Lithuanian and English-Amharic. Using filtered N-best MT hypotheses for language modeling is found to perform better than just using the 1-best translation. Target language texts collected from the Web and filtered to select conversational-like data are used in several manners. In addition to using Web data for training the language model of the speech recognizer, we further investigate using this data to improve the language model and phrase table of the MT system to get better translations of the English data. Finally, generating text data with a character-based recurrent neural network is investigated. This approach allows new word forms to be produced, providing a way to reduce the out-of-vocabulary rate and thereby improve keyword spotting performance. We study how these different methods of language model data augmentation impact speech-to-text and keyword spotting performance for the Lithuanian and Amharic languages. The best results are obtained by combining all of the explored methods.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gorin16']);">.bib</a> [Gorin16] | <i class="icon-book"></i> <a href="/download/pdfs/Gorin16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gorin16']);">.pdf</a>        </div>
    </div>
</div>
<h3>2015</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseFraga15_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fraga15']);">
        Active Learning based data selection for limited resource STT and KWS
        </a>
    </div>
    <div id="collapseFraga15_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Thiago Fraga-Silva, Jean-Luc Gauvain, Lori Lamel, Antoine Laurent, Viet-Bac Le, Abdel Messaoudi
<p><em>Interspeech 2015, Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper presents first results in using active learning (AL) for training data selection in the context of the IARPA-Babel program. Given an initial training data set, we aim to automatically select additional data (from an untranscribed pool data set) for manual transcription. Initial and selected data are then used to build acoustic and language models for speech recognition. The goal of the AL task is to outperform a baseline system built using a pre-defined data selection with the same amount of data, the Very Limited Language Pack (VLLP) condition. AL methods based on different selection criteria have been explored. Compared to the VLLP baseline, improvements are obtained in terms of Word Error Rate and Actual Term Weighted Values for the Lithuanian language. A description of methods and an analysis of the results are given. The AL selection also outperforms the VLLP baseline for other IARPA- Babel languages, and will be further tested in the upcoming NIST OpenKWS 2015 evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fraga15']);">.bib</a> [Fraga15] | <i class="icon-book"></i> <a href="/download/pdfs/Fraga15.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fraga15']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseFraga15b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fraga15b']);">
        Improving data selection for low-resource STT and KWS
        </a>
    </div>
    <div id="collapseFraga15b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Thiago Fraga-Silva, Antoine Laurent, Jean-Luc Gauvain, Lori Lamel, Viet-Bac Le, Abdel Messaoudi
<p><em>ASRU 2015, 2015 IEEE Automatic Speech Recognition and Understanding Workshop</em></p>
<blockquote><p>This paper extends recent research on training data selection for speech transcription and keyword spotting system development. The techinques were explored in the context of the IARPA-Babel Active Learning (AL) task for 6 languages. Different selection criteria were explored with the goal of improving over a system built using a predefined 3 hour training data set. Four variants of the entropy-based criterion were explored: words, triphones, phones as well as the use of HMM-states previously introduced in (see IS 2015 bellow). The influence of the number of HMM-states was assessed as well as whether automatic or manual reference transcripts were used. The combination of selection criteria was investigated, and a novel multi-stage selection method proposed. These methods were also assessed using larger data sets than were permitted in the Babel AL task. Results are reported for the 6 languages. The multi-stage selection was also applied to the surprise language (Swahili) in the NIST OpenKWS 2015 evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fraga15b']);">.bib</a> [Fraga15b] | <i class="icon-book"></i> <a href="/download/pdfs/Fraga15b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fraga15b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14']);">
        Development of a Korean speech recognition system with little annontated data
        </a>
    </div>
    <div id="collapseLaurent14_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>SLTU 2014, Spoken Language Technologies for Under-resourced languages</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. Korean is an alpha-syllabary language spoken by about 78 million people worldwide.  As only a small amount of manually transcribed audio data were available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. The reported word and character error rates are estimates, as development corpus used in these experiments was also constructed from the untranscribed audio data, the web texts and automatic transcriptions. Several variants for unsupervised acoustic model training were compared to assess the influence of the vocabulary size (200k vs 2M), the type of language model (words vs characters), the acoustic unit (phonemes vs half-syllables), as well as incremental batch vs iterative decoding of the untranscribed audio corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14']);">.bib</a> [Laurent14] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14b']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseLaurent14b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bredin, H., Laurent, A., Sarkar, A., Le, V.-B., Barras, Claude, Rosset, Sophie
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ``who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification -- leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14b']);">.bib</a> [Laurent14b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14e_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14e']);">
        Boosting bonsai trees for efficient features combination : application to speaker role identification
        </a>
    </div>
    <div id="collapseLaurent14e_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Camelin, N., Raymond, C.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>In this article, we tackle the problem of speaker role detection from broadcast news shows. In the literature, many proposed solutions are based on the combination of various features coming from acoustic, lexical and semantic information with a machine learning algorithm. Many previous studies mention the use of boosting over decision stumps to combine efficiently these features. In this work, we propose a modification of this state-of-the-art machine learning algorithm changing the weak learner (decision stumps) by small decision trees, denoted bonsai trees. Experiments show that using bonsai trees as weak learners for the boosting algorithm largely improves both system error rate and learning time.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14e']);">.bib</a> [Laurent14e] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14e.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14e']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14d_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14d']);">
        Unsupervised Acoustic Model Training for the Korean Language
        </a>
    </div>
    <div id="collapseLaurent14d_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Hartmann, W., Lamel, L.
<p><em>ISCSLP@Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper investigates unsupervised training strategies for the Korean language in the context of the DGA RAPID Rapmat project. As with previous studies, we begin with only a small amount of manually transcribed data to build preliminary acoustic models. Using the initial models, a larger set of untranscribed audio data is decoded to produce approximate transcripts. We compare both GMM and DNN acoustic models for both the unsupervised transcription and the final recognition system. While the DNN acoustic models produce a lower word error rate on the test set, training on the transcripts from the GMM system provides the best overall performance. We also achieve better performance by expanding the original phone set. Finally, we examine the efficacy of automatically building a test set by comparing system performance both before and after manually correcting the test set.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14d']);">.bib</a> [Laurent14d] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14d.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14d']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14c_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14c']);">
        Improving recognition of proper nouns in ASR through generating and filtering phonetic transcriptions
        </a>
    </div>
    <div id="collapseLaurent14c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Deléglise, P.
<p><em>In Computer Speech And Language</em></p>
<blockquote><p>Accurate phonetic transcription of proper nouns can be an important resource for commercial applications that embed speech technologies, such as audio indexing and vocal phone directory lookup. However, an accurate phonetic transcription is more difficult to obtain for proper nouns than for regular words. Indeed, phonetic transcription of a proper noun depends on both the origin of the speaker pronouncing it and the origin of the proper noun itself.This work proposes a method that allows the extraction of phonetic transcriptions of proper nouns using actual utterances of those proper nouns, thus yielding transcriptions based on practical use instead of mere pronunciation rules.The proposed method consists in a process that first extracts phonetic transcriptions, and then iteratively filters them. In order to initialize the process, an alignment dictionary is used to detect word boundaries. A rule-based grapheme-to-phoneme generator (LIA_PHON), a knowledge-based approach (JSM), and a Statistical Machine Translation based system were evaluated for this alignment.  As a result, compared to our reference dictionary (BDLEX supplemented by LIA_PHON for missing words) on the ESTER 1 French broadcast news corpus, we were able to significantly decrease the Word Error Rate (WER) on segments of speech with proper nouns, without negatively affecting the WER on the rest of the corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14c']);">.bib</a> [Laurent14c] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14c']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j5_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j5']);">
        Décodage hybride dans les SRAP pour l'indexation automatique de documents multimédia
        </a>
    </div>
    <div id="collapseLaurent14j5_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouaziz, M., Laurent, A., Estève, Y.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Certains Systèmes de Reconnaissance Automatique de la Parole (SRAP) atteignent des taux d'erreur de l'ordre de 10%. Toutefois, notamment dans le cadre de l'indexation automatique des documents multimédia sur le web, les SRAP se trouvent face à la problématique des mots hors-vocabulaire. En effet, les entités nommées en constituent une grande partie et sont remarquablement importantes pour les tâches d'indexation. Nous mettons en œuvre, dans ce travail, la solution du décodage hybride en utilisant les syllabes comme unités sous-lexicales. Cette méthode est intégrée au sein du SRAP LIUM'08 développé par le Laboratoire d'Informatique de l'Université du Maine. Avec une légère dégradation de la performance générale du système, environ 31% des noms de personne hors vocabulaire sont correctement reconnus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j5']);">.bib</a> [Laurent14j5] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j5.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j5']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j4_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j4']);">
        Traduction de la parole dans le projet RAPMAT
        </a>
    </div>
    <div id="collapseLaurent14j4_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bonneau-Maynard, H., Segal, N., Bilinski, E., Gauvain, J.-L., Gong, L., Lamel, L., Laurent, A., Yvon, F., Despres, J., Josse, Y., Le, V.-B.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Le projet RAPMAT vise à développer des systèmes de traduction de la parole en s’intéressant aux deux traitements constitutifs de la chaîne complète : la reconnaissance de la parole (RAP) et la traduction (TA). Dans la situation classique, les modèles statistiques utilisés par les deux systèmes sont estimés indépendemment, à partir de données de différentes natures (transcriptions manuelles de données de parole pour la RAP et corpus bilingues issus de données textuelles pour la TA). Nous proposons une approche semi-supervisée pour l'adaptation des modèles de traduction à la traduction de parole, dans laquelle les modèles de TA sont entraînés en intégrant des transcriptions manuelles et automatiques de la parole  traduites automatiquement. L'approche est expérimentée sur la direction de traduction français vers anglais. Un prototype de démonstration sur smartphones, incluant notamment la traduction de parole pour les paires de langues français/anglais et français/chinois a été développé pour permettre la collecte de données.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j4']);">.bib</a> [Laurent14j4] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j4.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j4']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j3_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j3']);">
        Développement d'un système de reconnaissance automatique de la parole en coréen avec peu de ressources annotées
        </a>
    </div>
    <div id="collapseLaurent14j3_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Ce papier décrit le développement d'un système de reconnaissance automatique de la parole pour le coréen. Le coréen est une langue alpha-syllabique, parlée par environ 78 millions de personnes dans le monde. Le développement de ce système a été mené en utilisant très peu de données annotées manuellement. Les modèles acoustiques ont été adaptés de manière non supervisée en utilisant des données provenant de différents sites d'actualités coréens. Le corpus de développement contient des transcriptions approximatives des documents audio : il s'agit d'un corpus transcrit automatiquement et aligné avec des données provenant des mêmes sites Internet. Nous comparons différentes approches dans ce travail, à savoir, des modèles de langue utilisant des unités différentes pour l'apprentissage non supervisé et pour le décodage (des caractères et des mots avec des vocabulaires de différentes tailles), l'utilisation de phonèmes et d'unités ``demi-syllabiques'' et deux approches différentes d'apprentissage non supervisé.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j3']);">.bib</a> [Laurent14j3] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j3.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j3']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j2_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j2']);">
        Analyse du corpus MATRICE : exploration et classification automatique d'archives audiovisuelles de 1930 à 2012
        </a>
    </div>
    <div id="collapseLaurent14j2_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Guinaudeau, C., Roy, A.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Cet article décrit les méthodes mises en place pour permettre l'analyse d'un corpus composé de documents audiovisuels diffusés au cours des 80 dernières années : le corpus MATRICE. Nous proposons une exploration des données permettant de mettre en évidence les différents thèmes et évènements abordés dans le corpus. Cette exploration est, dans un premier temps, effectuée sur des notices documentaires produites manuellement par les documentalistes de l'Institut National de l'Audiovisuel. Puis, nous montrons, grâce à une étude qualitative et une technique de clustering automatique, que les transcriptions automatiques permettent également d'effectuer une analyse du corpus faisant émerger des thèmes cohérents avec les données traitées.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j2']);">.bib</a> [Laurent14j2] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j2.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j2']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent14j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j1']);">
        Boosting de bonzaï pour la combinaison efficace de descripteurs : application à l'identification du rôle du locuteur
        </a>
    </div>
    <div id="collapseLaurent14j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Camelin, N., Raymond, C.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Dans ce travail, nous nous intéressons au problème de la détection du rôle du locuteur dans les émissions d'actualités radiotélévisées. Dans la littérature, les solutions proposées sont de combiner des indicateurs variés provenant de l'acoustique, de la transcription et/ou de son analyse par des méthodes d'apprentissage automatique. De nombreuses études font ressortir l'algorithme de boosting sur des règles de décision simples comme l'un des plus efficaces à combiner ces différents descripteurs. Nous proposons ici une modification de cet algorithme état-de-l'art en remplaçant ces règles de décision simples par des mini arbres de décision que nous appelons bonzaïs. Les expériences comparatives menées sur le corpus EPAC montrent que cette modification améliore largement les performances du système tout en réduisant le temps d'apprentissage de manière conséquente.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j1']);">.bib</a> [Laurent14j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseguinaudeau14_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'guinaudeau14']);">
        LIMSI @ MediaEval SED 2014
        </a>
    </div>
    <div id="collapseguinaudeau14_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Guinaudeau, C., Laurent, A., Bredin, H.
<p><em>MediaEval 2014 Social Event Detection Task. Working Notes Proceedings</em></p>
<blockquote><p>This paper provides an overview of the Social Event Detection (SED) system developed at LIMSI for the 2014 campaign. Our approach is based on a hierarchical agglomerative clustering that uses textual metadata, user-based knowledge and geographical information. These different sources of knowledge, either used separately or in cascade, reach good results for the full clustering subtask with a normalized mutual information equal to 0.95 and F1 scores greater than 0.82 for our best run.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'guinaudeau14']);">.bib</a> [guinaudeau14] | <i class="icon-book"></i> <a href="/download/pdfs/guinaudeau14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'guinaudeau14']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent12_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12']);">
        Combining transcription-based and acoustic-based speaker identifications for broadcast news
        </a>
    </div>
    <div id="collapseLaurent12_All" class="accordion-body collapse">
        <div class="accordion-inner">
        El-Khoury, E., Laurent, A., Meignier, S., Petitrenaud, S.
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12']);">.bib</a> [Laurent12] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent12j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12j1']);">
        Combinaison d'approches pour la reconnaissance du rôle des locuteurs
        </a>
    </div>
    <div id="collapseLaurent12j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Dufour, R., Laurent, A., Estève, Y.
<p><em>JEP 2012, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12j1']);">.bib</a> [Laurent12j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent11_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent11']);">
        Computer-assisted transcription of speech based on confusion network reordering
        </a>
    </div>
    <div id="collapseLaurent11_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>ICASSP 2011, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent11']);">.bib</a> [Laurent11] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent11.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent11']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseEstève10_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Estève10']);">
        Some recent research work at LIUM based on the use of CMU Sphinx
        </a>
    </div>
    <div id="collapseEstève10_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Estève, Y., Deléglise, P., Meignier, S., Petitrenaud, S., Schwenk, H., Barrault, L., Bougares, F., Dufour, R., Jousse, V., Laurent, A., Rousseau, A.
<p><em>Workshop CMU SPU</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Estève10']);">.bib</a> [Estève10] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent10j1_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10j1']);">
        Réordonnancement automatique d'hypothèses pour l'assistance à la transcription de la parole
        </a>
    </div>
    <div id="collapseLaurent10j1_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Meignier, S., Deléglise, P.
<p><em>JEP 2010, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10j1']);">.bib</a> [Laurent10j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent10-b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10-b']);">
        Acoustics-Based Phonetic Transcription Method for Proper Nouns
        </a>
    </div>
    <div id="collapseLaurent10-b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>Interspeech 2010, 11th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10-b']);">.bib</a> [Laurent10-b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10-b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10-b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent09b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09b']);">
        Grapheme to phoneme conversion using an SMT system
        </a>
    </div>
    <div id="collapseLaurent09b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Deléglise, P., Meignier, S.
<p><em>Interspeech 2009, 10th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09b']);">.bib</a> [Laurent09b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent09_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09']);">
        Iterative filtrering of phonetic transcriptions of proper nouns
        </a>
    </div>
    <div id="collapseLaurent09_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>ICASSP 2009, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09']);">.bib</a> [Laurent09] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent08b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08b']);">
        Combinaison de systèmes pour la phonétisation automatique de noms propres
        </a>
    </div>
    <div id="collapseLaurent08b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., and Meignier, S., Estève, Y., Deléglise, P.
<p><em>JEP 2008, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08b']);">.bib</a> [Laurent08b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLaurent08_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08']);">
        Combined systems for automatic phonetic transcription of proper nouns
        </a>
    </div>
    <div id="collapseLaurent08_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>LREC 2008, Language Resources and Evaluation Conference</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08']);">.bib</a> [Laurent08] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Journalarticles">
<div class="accordion" id="accordionJournalarticles">
<h3>2021</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapsecarrive21_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'carrive21']);">
        Transdisciplinary Analysis of a Corpus of French Newsreels: The ANTRACT Project
        </a>
    </div>
    <div id="collapsecarrive21_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Jean Carrive, Abdelkrim Beloued, Pascale Goetschel, Serge Heiden, Antoine Laurent, Pasquale Lisena, Franck Mazuet, Sylvain Meignier, Bénédicte Pincemin, Géraldine Poels, Raphaël Troncy
<p><em>Digital Humanities Quarterly</em></p>
<blockquote><p>The ANTRACT project is a cross-disciplinary apparatus dedicated to the analysis of the French newsreel company Les Actualités Françaises (1945-1969) and its film productions. Founded during the liberation of France, this state-owned company filmed more than 20,000 news reports shown in French cinemas and throughout the world over its 24 years of activity. The project brings together research organizations with a dual historical and technological perspective. ANTRACT’s goal is to study the production process, the film content, the way historical events are represented and the audience reception of Les Actualités Françaises newsreels using innovative AI-based data processing tools developed by partners specialized in image, audio, and text analysis. This article focuses on the data processing apparatus and tools of the project. Automatic content analysis is used to select data, to segment video units and typescript images, and to align them with their archival description. Automatic speech recognition provides a textual representation and natural language processing can extract named entities from the voice-over recording; automatic visual analysis is applied to detect and recognize faces of well-known characters in videos. These multifaceted data can then be queried and explored with the TXM text-mining platform. The results of these automatic analysis processes are feeding the Okapi platform, a client-server software that integrates documentation, information retrieval, and hypermedia capabilities within a single environment based on the Semantic Web standards. The complete corpus of Les Actualités Françaises, enriched with data and metadata, will be made available to the scientific community by the end of the project.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'carrive21']);">.bib</a> [carrive21] | <i class="icon-book"></i> <a href="/download/pdfs/carrive21.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'carrive21']);">.pdf</a>        </div>
    </div>
</div>
<h3>2020</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapsemontresor20b_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'montresor20b']);">
        Computational de-noising based on deep learning for phase data in digital holographic interferometry
        </a>
    </div>
    <div id="collapsemontresor20b_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Silvio Montrésor, Marie Tahon, Antoine Laurent, Pascal Picart
<p><em>APL Photonics AIP Publishing LLC</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'montresor20b']);">.bib</a> [montresor20b] |         </div>
    </div>
</div>
<h3>2019</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapsegagnepain19_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'gagnepain19']);">
        Collective memory shapes the organization of individual memories in the medial prefrontal cortex
        </a>
    </div>
    <div id="collapsegagnepain19_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierre Gagnepain, Thomas Vallée, Serge Heiden, Matthieu Decorde, Jean-Luc Gauvain, Antoine Laurent, Carine Klein-Peschanski, Fausto Viader, Denis Peschanski, Francis Eustache
<p><em>Nature Human Behaviour</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'gagnepain19']);">.bib</a> [gagnepain19] | <i class="icon-book"></i> <a href="/download/pdfs/gagnepain19.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'gagnepain19']);">.pdf</a>        </div>
    </div>
</div>
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseLaurent14c_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14c']);">
        Improving recognition of proper nouns in ASR through generating and filtering phonetic transcriptions
        </a>
    </div>
    <div id="collapseLaurent14c_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Deléglise, P.
<p><em>In Computer Speech And Language</em></p>
<blockquote><p>Accurate phonetic transcription of proper nouns can be an important resource for commercial applications that embed speech technologies, such as audio indexing and vocal phone directory lookup. However, an accurate phonetic transcription is more difficult to obtain for proper nouns than for regular words. Indeed, phonetic transcription of a proper noun depends on both the origin of the speaker pronouncing it and the origin of the proper noun itself.This work proposes a method that allows the extraction of phonetic transcriptions of proper nouns using actual utterances of those proper nouns, thus yielding transcriptions based on practical use instead of mere pronunciation rules.The proposed method consists in a process that first extracts phonetic transcriptions, and then iteratively filters them. In order to initialize the process, an alignment dictionary is used to detect word boundaries. A rule-based grapheme-to-phoneme generator (LIA_PHON), a knowledge-based approach (JSM), and a Statistical Machine Translation based system were evaluated for this alignment.  As a result, compared to our reference dictionary (BDLEX supplemented by LIA_PHON for missing words) on the ESTER 1 French broadcast news corpus, we were able to significantly decrease the Word Error Rate (WER) on segments of speech with proper nouns, without negatively affecting the WER on the rest of the corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14c']);">.bib</a> [Laurent14c] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14c']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Bookchapters">
<div class="accordion" id="accordionBookchapters">
</div>
</div>
<div class="tab-pane fade in" id="Conferenceandworkshopproceedings">
<div class="accordion" id="accordionConferenceandworkshopproceedings">
<h3>2021</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsepelloin21_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'pelloin21']);">
        End2End Acoustic to Semantic Transduction
        </a>
    </div>
    <div id="collapsepelloin21_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Valentin Pelloin, Nathalie Camelin, Antoine Laurent, Renato de Mori, Antoine Caubrière, Yannick Estève, Sylvain Meignier
<p><em>ICASSP 2021</em></p>
<blockquote><p>In this paper, we propose a novel end-to-end sequence-to-sequence spoken language understanding model using an attention mechanism. It reliably selects contextual acoustic features in order to hypothesize semantic contents. An initial architecture capable of extracting all pronounced words and concepts from acoustic spans is designed and tested. With a shallow fusion language model, this system reaches a 13.6 concept error rate (CER) and an 18.5 concept value error rate (CVER) on the French MEDIA corpus, achieving an absolute 2.8 points reduction compared to the state-of-the-art. Then, an original model is proposed for hypothesizing concepts and their values. This transduction reaches a 15.4 CER and a 21.6 CVER without any new type of context.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'pelloin21']);">.bib</a> [pelloin21] |         </div>
    </div>
</div>
<h3>2020</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsemontresor20_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'montresor20']);">
        Deep learning-based speckle decorrelation denoising for wide-field optical metrology
        </a>
    </div>
    <div id="collapsemontresor20_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Silvio Montrésor, Marie Tahon, Antoine Laurent, Picart Pascal
<p><em>SPIE Photonics Europe International Symposium</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'montresor20']);">.bib</a> [montresor20] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsemdhaffar2020_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'mdhaffar2020']);">
        A Multimodal Educational Corpus of Oral Courses: Annotation, Analysis and Case Study
        </a>
    </div>
    <div id="collapsemdhaffar2020_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima mdhaffar, Yannick Estève, Antoine Laurent, Nicolas Hernandez, Richard Dufour, Delphine Charlet, Geraldine Damnati, Solen Quiniou, Nathalie Camelin
<p><em>LREC 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'mdhaffar2020']);">.bib</a> [mdhaffar2020] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsecaubriere2020b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020b']);">
        ERROR ANALYSIS APPLIED TO END-TO-END SPOKEN LANGUAGE UNDERSTANDING
        </a>
    </div>
    <div id="collapsecaubriere2020b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sahar Ghannay, Natalia Tomashenko, Renato De Mori, Antoine Laurent, Emmanuel Morin, Yannick Estève
<p><em>ICASSP 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020b']);">.bib</a> [caubriere2020b] | <i class="icon-book"></i> <a href="/download/pdfs/caubriere2020b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'caubriere2020b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsecaubriere2020_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020']);">
        Where are we in Named Entity Recognition from Speech?
        </a>
    </div>
    <div id="collapsecaubriere2020_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sophie Rosset, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>LREC 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020']);">.bib</a> [caubriere2020] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsecaubriere2020jep_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020jep']);">
        Où en sommes-nous dans la reconnaissance des entités nommées structurées à partir de la parole ?
        </a>
    </div>
    <div id="collapsecaubriere2020jep_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Sophie Rosset, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>JEP 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020jep']);">.bib</a> [caubriere2020jep] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsecaubriere2020int_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2020int']);">
        Confidence measure for speech-to-concept end-to-end spoken language understanding
        </a>
    </div>
    <div id="collapsecaubriere2020int_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Yannick Estève, Antoine Laurent, Emmanuel Morin
<p><em>Interspeech 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2020int']);">.bib</a> [caubriere2020int] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsedolfing20_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'dolfing20']);">
        The "ScribbleLens" Dutch historical handwriting corpus
        </a>
    </div>
    <div id="collapsedolfing20_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hans Dolfing, Jérome Bellegarda, Jan Chorowski, Ricard Marxer, Antoine Laurent
<p><em>ICFHR 2020</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'dolfing20']);">.bib</a> [dolfing20] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapselancucki20_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'lancucki20']);">
        Robust Training of Vector Quantized Bottleneck Models
        </a>
    </div>
    <div id="collapselancucki20_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Adrian Łancucki, Jan Chorowski, Guillaume Sanchez, Ricard Marxer, Nanxin Chen, Hans J G A Dolfing, Sameer Khurana, Tanel Alumäe, Antoine Laurent
<p><em>IJCNN 2020</em></p>
<blockquote><p>In this paper we demonstrate methods for reliable and efficient training of discrete representation using Vector-Quantized Variational Auto-Encoder models (VQ-VAEs). Discrete latent variable models have been shown to learn nontrivial representations of speech, applicable to unsupervised voice conversion and reaching state-of-the-art performance on unit discovery tasks. For unsupervised representation learning, they became viable alternatives to continuous latent variable models such as the Variational Auto-Encoder (VAE). However, training deep discrete variable models is challenging, due to the inherent non-differentiability of the discretization operation. In this paper we focus on VQ-VAE, a state-of-the-art discrete bottleneck model shown to perform on par with its continuous counterparts. It quantizes encoder outputs with on-line k-means clustering. We show that the codebook learning can suffer from poor initialization and non-stationarity of clustered encoder outputs. We demonstrate that these can be successfully overcome by increasing the learning rate for the codebook and periodic date-dependent codeword re-initialization. As a result, we achieve more robust training across different tasks, and significantly increase the usage of latent codewords even for large codebooks. This has practical benefit, for instance, in unsupervised representation learning, where large codebooks may lead to disentanglement of latent representations.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'lancucki20']);">.bib</a> [lancucki20] | <i class="icon-book"></i> <a href="/download/pdfs/lancucki20.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'lancucki20']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsekhurana20b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'khurana20b']);">
        CSTNet: Contrastive Speech Translation Network for Self-Supervised Speech Representation Learning
        </a>
    </div>
    <div id="collapsekhurana20b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Sameer Khurana, Antoine Laurent, James Glass
<p><em>Arxiv</em></p>
<blockquote><p>More than half of the 7,000 languages in the world are in imminent danger of going extinct. Traditional methods of documenting language proceed by collecting audio data followed by manual annotation by trained linguists at different levels of granularity. This time consuming and painstaking process could benefit from machine learning. Many endangered languages do not have any orthographic form but usually have speakers that are bi-lingual and trained in a high resource language. It is relatively easy to obtain textual translations corresponding to speech. In this work, we provide a multimodal machine learning framework for speech representation learning by exploiting the correlations between the two modalities namely speech and its corresponding text translation. Here, we construct a convolutional neural network audio encoder capable of extracting linguistic representations from speech. The audio encoder is trained to perform a speech-translation retrieval task in a contrastive learning framework. By evaluating the learned representations on a phone recognition task, we demonstrate that linguistic representations emerge in the audio encoder's internal representations as a by-product of learning to perform the retrieval task.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'khurana20b']);">.bib</a> [khurana20b] | <i class="icon-book"></i> <a href="/download/pdfs/khurana20b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'khurana20b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsekhurana20_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'khurana20']);">
        A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning
        </a>
    </div>
    <div id="collapsekhurana20_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Sameer Khurana, Antoine Laurent, Wei-Ning Hsu, Jan Chorowski, Adrian Lancucki, Ricard Marxer, James Glass
<p><em>Interspeech 2020</em></p>
<blockquote><p>Probabilistic Latent Variable Models (LVMs) provide an alternative to self-supervised learning approaches for linguistic representation learning from speech. LVMs admit an intuitive probabilistic interpretation where the latent structure shapes the information extracted from the signal. Even though LVMs have recently seen a renewed interest due to the introduction of Variational Autoencoders (VAEs), their use for speech representation learning remains largely unexplored. In this work, we propose Convolutional Deep Markov Model (ConvDMM), a Gaussian state-space model with non-linear emission and transition functions modelled by deep neural networks. This unsupervised model is trained using black box variational inference. A deep convolutional neural network is used as an inference network for structured variational approximation. When trained on a large scale speech dataset (LibriSpeech), ConvDMM produces features that significantly outperform multiple self-supervised feature extracting methods on linear phone classification and recognition on the Wall Street Journal dataset. Furthermore, we found that ConvDMM complements self-supervised methods like Wav2Vec and PASE, improving on the results achieved with any of the methods alone. Lastly, we find that ConvDMM features enable learning better phone recognizers than any other features in an extreme low-resource regime with few labeled training examples.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'khurana20']);">.bib</a> [khurana20] | <i class="icon-book"></i> <a href="/download/pdfs/khurana20.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'khurana20']);">.pdf</a>        </div>
    </div>
</div>
<h3>2019</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMdhaffar19b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar19b']);">
        Apport de l’adaptation automatique des modèles de langage pour la reconnaissance de la parole : évaluation qualitative extrinsèque dans un contexte de traitement de cours magistraux.
        </a>
    </div>
    <div id="collapseMdhaffar19b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima Mdhaffar, Yannick Estève, Nicolas Hernandez, Antoine Laurent, Solen Quiniou
<p><em>26e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2019)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar19b']);">.bib</a> [Mdhaffar19b] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsecaubriere2019curriculum_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'caubriere2019curriculum']);">
        Curriculum d'apprentissage: reconnaissance d'entités nommées pour l'extraction de concepts sémantiques
        </a>
    </div>
    <div id="collapsecaubriere2019curriculum_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Caubrière, Antoine, Tomashenko, Natalia, Estève, Yannick, Laurent, Antoine, Morin, Emmanuel
<p><em>26e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2019)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'caubriere2019curriculum']);">.bib</a> [caubriere2019curriculum] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseCaubriere2019_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Caubriere2019']);">
        Curriculum-based transfer learning for an effective end-to-end spoken language understanding and domain portability
        </a>
    </div>
    <div id="collapseCaubriere2019_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Caubrière, Natalia Tomashenko, Antoine LAURENT, Emmanuel Morin, Nathalie Camelin, Yannick Estève
<p><em>Interspeech 2019, Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Caubriere2019']);">.bib</a> [Caubriere2019] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMdhaffar2019_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar2019']);">
        Qualitative evaluation of ASR adaptation in a lecture context: Application to the PASTEL corpus
        </a>
    </div>
    <div id="collapseMdhaffar2019_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Salima mdhaffar, Yannick Estève, Nicolas Hernandez, Antoine LAURENT, Solen Quiniou
<p><em>Interspeech 2019, Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar2019']);">.bib</a> [Mdhaffar2019] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsetomashenko2019recent_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'tomashenko2019recent']);">
        Recent Advances in End-to-End Spoken Language Understanding
        </a>
    </div>
    <div id="collapsetomashenko2019recent_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Tomashenko, Natalia, Caubrière, Antoine, Estève, Yannick, Laurent, Antoine, Morin, Emmanuel
<p><em>International Conference on Statistical Language and Speech Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'tomashenko2019recent']);">.bib</a> [tomashenko2019recent] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsechorowski19_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'chorowski19']);">
        Unsupervised Neural Segmentation and Clustering for Unit Discovery in Sequential Data
        </a>
    </div>
    <div id="collapsechorowski19_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Jan Chorowski, Nanxin Chen, Ricard Marxer, Hans J G A Dolfing, Adrian Ła\'ncucki, Guillaume Sanchez, Tanel Alum\"ae, Antoine Laurent
<p><em>NeurIPS 2019 workshop - Perception as generative reasoning - Structure, Causality, Probability</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'chorowski19']);">.bib</a> [chorowski19] |         </div>
    </div>
</div>
<h3>2018</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMdhaffar18b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar18b']);">
        Le corpus PASTEL pour le traitement automatique de cours magistraux.
        </a>
    </div>
    <div id="collapseMdhaffar18b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Mdhaffar, A. Laurent, Y. Estève
<p><em>25e conférence sur le Traitement Automatique des Langues Naturelles (TALN 2018)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar18b']);">.bib</a> [Mdhaffar18b] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMdhaffar2018_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Mdhaffar2018']);">
        Etude de performance des réseaux neuronaux récurrents dans le cadre de la campagne d'évaluation Multi-Genre Broadcast challenge 3 (MGB3)
        </a>
    </div>
    <div id="collapseMdhaffar2018_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Mdhaffar, A. Laurent, Y. Estève
<p><em>XXXIIe Journees d'Etudes sur la Parole (JEP 2018)</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Mdhaffar2018']);">.bib</a> [Mdhaffar2018] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGhannay2018_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ghannay2018']);">
        End-to-end named entity and semantic concept extraction from speech
        </a>
    </div>
    <div id="collapseGhannay2018_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        S. Gannay, A. Caubriere, Y. Estève, N. Camelin, E. Simmonet, A. Laurent
<p><em>IEEE Spoken Language Technology Workshop</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ghannay2018']);">.bib</a> [Ghannay2018] |         </div>
    </div>
</div>
<h3>2017</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseHuang17_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Huang17']);">
        AN INVESTIGATION INTO LANGUAGE MODEL DATA AUGMENTATION FOR LOW-RESOURCED STT AND KWS
        </a>
    </div>
    <div id="collapseHuang17_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Guangpu Huang, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain, Antoine Laurent, Rasa Lileikyte, Abdel Massouadi
<p><em>ICASSP 2017, The 42st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>This paper reports on investigations of using two tecnniques for language model text data augmentation for low-resourced automatic speech recognition and keyword search. Low-resourced languages are characterized by limited training materials, which typically results in high out-of-vocabulary (OOV) rates and poor language model estimates. One technique makes use of recurrent neural networks (RNNs) using word or subword units. Word-based RNNs keep the same system vocabulary, so they cannot reduce the OOV, whereas subword units can reduce the OOV but generate many false combinations. A complementary technique is based on automatic machine translation, which requires parallel texts and is able to add words to the vocabulary. These methods were accessed on 10 languages in the context of the Babel program and NIST OpenKWS evaluation. Although improvements vary across languages with both methods, small gains were generally observed in terms of word error rate reduction and improved keyword search performance.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Huang17']);">.bib</a> [Huang17] | <i class="icon-book"></i> <a href="/download/pdfs/Huang17.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Huang17']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLileikyte17_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Lileikyte17']);">
        EFFECTIVE KEYWORD SEARCH FOR LOW-RESOURCED CONVERSATIONAL SPEECH
        </a>
    </div>
    <div id="collapseLileikyte17_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Rasa Lileikyte, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain, Antoine Laurent, Guangpu Huang
<p><em>ICASSP 2017, The 42st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>In this paper we aim to enhance keyword search for conversational telephone speech under low-resourced conditions. Two techniques to improve the detection of out-of-vocabulary keywords are assessed in this study: using extra text resources to augment the lexicon and language model, and via subword units for keyword search. Two approaches for data augmentation are explored to extend the limited amount of transcribed conversational speech: using conversational-like Web data and texts generated by recurrent neural networks. Contrastive comparisons of subword-based systems are performed to evaluate the benefits of multiple subword decodings and single decoding. Keyword search results are reported for all the techniques, but only some improve performance. Results are reported for the Mongolian and Igbo languages using data from the 2016 Babel program.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Lileikyte17']);">.bib</a> [Lileikyte17] | <i class="icon-book"></i> <a href="/download/pdfs/Lileikyte17.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Lileikyte17']);">.pdf</a>        </div>
    </div>
</div>
<h3>2016</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGelly16_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gelly16']);">
        Language Recognition for Dialects and Closely Related Languages
        </a>
    </div>
    <div id="collapseGelly16_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        G. Gelly, J.L. Gauvain, L. Lamel, A. Laurent, V.B. Le, A. Messaoudi
<p><em>Odyssey 2016</em></p>
<blockquote><p>This paper describes our development work to design a language recognition system that can discriminate closely related languages and dialects of the same language. The work was a joint effort by LIMSI and Vocapia Research in preparation for the NIST 2015 Language Recognition Evaluation (LRE). The language recognition system results from a fusion of four core classifiers: a phonotactic component using DNN acoustic models, two purely acoustic components using a RNN model and and i-vector model, and a lexical component. Each component generates language posterior probabilities optimized to maximize the LID NCE, making their combination simple and robust. The motivation for using multiple components representing different speech knowledge is that some dialect distinctions may not be manifest at the acoustic level. We report experiments on the NIST LRE15 data and provide an analysis of the results and some post-evaluation contrasts.  The 2015 LRE task focused on the identification of 20 languages clustered in 6 groups (Arabic, Chinese, English, French, Slavic and Iberic) of similar languages. Results are reported using the NIST Cavg metric which served as the primary metric for the OpenLRE15 evaluation. Results are also reported for the EER and the LER.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gelly16']);">.bib</a> [Gelly16] | <i class="icon-book"></i> <a href="/download/pdfs/Gelly16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gelly16']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent16_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent16']);">
        INVESTIGATING TECHNIQUES FOR LOW RESOURCE CONVERSATIONAL SPEECH RECOGNITION
        </a>
    </div>
    <div id="collapseLaurent16_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Antoine Laurent, Thiago Fraga-Silva, Lori Lamel, Jean-Luc Gauvain
<p><em>ICASSP 2016, The 41st IEEE International Conference on Acoustics, Speech and Signal Processing</em></p>
<blockquote><p>In this paper we investigate various techniques in order to build effective speech to text (STT) and keyword search (KWS) systems for low resource conversational speech. Subword decoding and graphemic mappings were assessed in order to detect out-of-vocabulary keywords. To deal with the limited amount of transcribed data, semi-supervised training and data selection methods were investigated. Robust acoustic features produced via data augmentation were evaluated for acoustic modeling. For language modeling, automatically retrieved conversational-like Webdata was used, as well as neural network based models. We report STT improvements with all the techniques, but interestingly only some improve KWS performance. Results are reported for the Swahili language in the context of the 2015 OpenKWS Evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent16']);">.bib</a> [Laurent16] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent16']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGorin16_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gorin16']);">
        Language Model Data Augmentation for Keyword Spotting in Low-Resourced Training Conditions
        </a>
    </div>
    <div id="collapseGorin16_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        A. Gorin, R. Lileikyte, G. Huang, L. Lamel, J.L. Gauvain, A. Laurent
<p><em>Interspeech 2016, Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This research extends our earlier work on using machine translation (MT) and word-based recurrent neural networks to augment language model training data for keyword search in conversational Cantonese speech. MT-based data augmentation is applied to two language pairs: English-Lithuanian and English-Amharic. Using filtered N-best MT hypotheses for language modeling is found to perform better than just using the 1-best translation. Target language texts collected from the Web and filtered to select conversational-like data are used in several manners. In addition to using Web data for training the language model of the speech recognizer, we further investigate using this data to improve the language model and phrase table of the MT system to get better translations of the English data. Finally, generating text data with a character-based recurrent neural network is investigated. This approach allows new word forms to be produced, providing a way to reduce the out-of-vocabulary rate and thereby improve keyword spotting performance. We study how these different methods of language model data augmentation impact speech-to-text and keyword spotting performance for the Lithuanian and Amharic languages. The best results are obtained by combining all of the explored methods.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gorin16']);">.bib</a> [Gorin16] | <i class="icon-book"></i> <a href="/download/pdfs/Gorin16.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gorin16']);">.pdf</a>        </div>
    </div>
</div>
<h3>2015</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseFraga15_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fraga15']);">
        Active Learning based data selection for limited resource STT and KWS
        </a>
    </div>
    <div id="collapseFraga15_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Thiago Fraga-Silva, Jean-Luc Gauvain, Lori Lamel, Antoine Laurent, Viet-Bac Le, Abdel Messaoudi
<p><em>Interspeech 2015, Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper presents first results in using active learning (AL) for training data selection in the context of the IARPA-Babel program. Given an initial training data set, we aim to automatically select additional data (from an untranscribed pool data set) for manual transcription. Initial and selected data are then used to build acoustic and language models for speech recognition. The goal of the AL task is to outperform a baseline system built using a pre-defined data selection with the same amount of data, the Very Limited Language Pack (VLLP) condition. AL methods based on different selection criteria have been explored. Compared to the VLLP baseline, improvements are obtained in terms of Word Error Rate and Actual Term Weighted Values for the Lithuanian language. A description of methods and an analysis of the results are given. The AL selection also outperforms the VLLP baseline for other IARPA- Babel languages, and will be further tested in the upcoming NIST OpenKWS 2015 evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fraga15']);">.bib</a> [Fraga15] | <i class="icon-book"></i> <a href="/download/pdfs/Fraga15.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fraga15']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseFraga15b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fraga15b']);">
        Improving data selection for low-resource STT and KWS
        </a>
    </div>
    <div id="collapseFraga15b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Thiago Fraga-Silva, Antoine Laurent, Jean-Luc Gauvain, Lori Lamel, Viet-Bac Le, Abdel Messaoudi
<p><em>ASRU 2015, 2015 IEEE Automatic Speech Recognition and Understanding Workshop</em></p>
<blockquote><p>This paper extends recent research on training data selection for speech transcription and keyword spotting system development. The techinques were explored in the context of the IARPA-Babel Active Learning (AL) task for 6 languages. Different selection criteria were explored with the goal of improving over a system built using a predefined 3 hour training data set. Four variants of the entropy-based criterion were explored: words, triphones, phones as well as the use of HMM-states previously introduced in (see IS 2015 bellow). The influence of the number of HMM-states was assessed as well as whether automatic or manual reference transcripts were used. The combination of selection criteria was investigated, and a novel multi-stage selection method proposed. These methods were also assessed using larger data sets than were permitted in the Babel AL task. Results are reported for the 6 languages. The multi-stage selection was also applied to the surprise language (Swahili) in the NIST OpenKWS 2015 evaluation.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fraga15b']);">.bib</a> [Fraga15b] | <i class="icon-book"></i> <a href="/download/pdfs/Fraga15b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fraga15b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14']);">
        Development of a Korean speech recognition system with little annontated data
        </a>
    </div>
    <div id="collapseLaurent14_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>SLTU 2014, Spoken Language Technologies for Under-resourced languages</em></p>
<blockquote><p>This paper investigates the development of a speech-to-text transcription system for the Korean language in the context of the DGA RAPID Rapmat project. Korean is an alpha-syllabary language spoken by about 78 million people worldwide.  As only a small amount of manually transcribed audio data were available, the acoustic models were trained on audio data downloaded from several Korean websites in an unsupervised manner, and the language models were trained on web texts. The reported word and character error rates are estimates, as development corpus used in these experiments was also constructed from the untranscribed audio data, the web texts and automatic transcriptions. Several variants for unsupervised acoustic model training were compared to assess the influence of the vocabulary size (200k vs 2M), the type of language model (words vs characters), the acoustic unit (phonemes vs half-syllables), as well as incremental batch vs iterative decoding of the untranscribed audio corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14']);">.bib</a> [Laurent14] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14b']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseLaurent14b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bredin, H., Laurent, A., Sarkar, A., Le, V.-B., Barras, Claude, Rosset, Sophie
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ``who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification -- leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14b']);">.bib</a> [Laurent14b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14e_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14e']);">
        Boosting bonsai trees for efficient features combination : application to speaker role identification
        </a>
    </div>
    <div id="collapseLaurent14e_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Camelin, N., Raymond, C.
<p><em>Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>In this article, we tackle the problem of speaker role detection from broadcast news shows. In the literature, many proposed solutions are based on the combination of various features coming from acoustic, lexical and semantic information with a machine learning algorithm. Many previous studies mention the use of boosting over decision stumps to combine efficiently these features. In this work, we propose a modification of this state-of-the-art machine learning algorithm changing the weak learner (decision stumps) by small decision trees, denoted bonsai trees. Experiments show that using bonsai trees as weak learners for the boosting algorithm largely improves both system error rate and learning time.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14e']);">.bib</a> [Laurent14e] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14e.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14e']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14d_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14d']);">
        Unsupervised Acoustic Model Training for the Korean Language
        </a>
    </div>
    <div id="collapseLaurent14d_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Hartmann, W., Lamel, L.
<p><em>ISCSLP@Interspeech 2014, 15th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper investigates unsupervised training strategies for the Korean language in the context of the DGA RAPID Rapmat project. As with previous studies, we begin with only a small amount of manually transcribed data to build preliminary acoustic models. Using the initial models, a larger set of untranscribed audio data is decoded to produce approximate transcripts. We compare both GMM and DNN acoustic models for both the unsupervised transcription and the final recognition system. While the DNN acoustic models produce a lower word error rate on the test set, training on the transcripts from the GMM system provides the best overall performance. We also achieve better performance by expanding the original phone set. Finally, we examine the efficacy of automatically building a test set by comparing system performance both before and after manually correcting the test set.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14d']);">.bib</a> [Laurent14d] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14d.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14d']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j5_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j5']);">
        Décodage hybride dans les SRAP pour l'indexation automatique de documents multimédia
        </a>
    </div>
    <div id="collapseLaurent14j5_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouaziz, M., Laurent, A., Estève, Y.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Certains Systèmes de Reconnaissance Automatique de la Parole (SRAP) atteignent des taux d'erreur de l'ordre de 10%. Toutefois, notamment dans le cadre de l'indexation automatique des documents multimédia sur le web, les SRAP se trouvent face à la problématique des mots hors-vocabulaire. En effet, les entités nommées en constituent une grande partie et sont remarquablement importantes pour les tâches d'indexation. Nous mettons en œuvre, dans ce travail, la solution du décodage hybride en utilisant les syllabes comme unités sous-lexicales. Cette méthode est intégrée au sein du SRAP LIUM'08 développé par le Laboratoire d'Informatique de l'Université du Maine. Avec une légère dégradation de la performance générale du système, environ 31% des noms de personne hors vocabulaire sont correctement reconnus.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j5']);">.bib</a> [Laurent14j5] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j5.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j5']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j4_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j4']);">
        Traduction de la parole dans le projet RAPMAT
        </a>
    </div>
    <div id="collapseLaurent14j4_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bonneau-Maynard, H., Segal, N., Bilinski, E., Gauvain, J.-L., Gong, L., Lamel, L., Laurent, A., Yvon, F., Despres, J., Josse, Y., Le, V.-B.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Le projet RAPMAT vise à développer des systèmes de traduction de la parole en s’intéressant aux deux traitements constitutifs de la chaîne complète : la reconnaissance de la parole (RAP) et la traduction (TA). Dans la situation classique, les modèles statistiques utilisés par les deux systèmes sont estimés indépendemment, à partir de données de différentes natures (transcriptions manuelles de données de parole pour la RAP et corpus bilingues issus de données textuelles pour la TA). Nous proposons une approche semi-supervisée pour l'adaptation des modèles de traduction à la traduction de parole, dans laquelle les modèles de TA sont entraînés en intégrant des transcriptions manuelles et automatiques de la parole  traduites automatiquement. L'approche est expérimentée sur la direction de traduction français vers anglais. Un prototype de démonstration sur smartphones, incluant notamment la traduction de parole pour les paires de langues français/anglais et français/chinois a été développé pour permettre la collecte de données.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j4']);">.bib</a> [Laurent14j4] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j4.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j4']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j3_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j3']);">
        Développement d'un système de reconnaissance automatique de la parole en coréen avec peu de ressources annotées
        </a>
    </div>
    <div id="collapseLaurent14j3_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Lamel, L.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Ce papier décrit le développement d'un système de reconnaissance automatique de la parole pour le coréen. Le coréen est une langue alpha-syllabique, parlée par environ 78 millions de personnes dans le monde. Le développement de ce système a été mené en utilisant très peu de données annotées manuellement. Les modèles acoustiques ont été adaptés de manière non supervisée en utilisant des données provenant de différents sites d'actualités coréens. Le corpus de développement contient des transcriptions approximatives des documents audio : il s'agit d'un corpus transcrit automatiquement et aligné avec des données provenant des mêmes sites Internet. Nous comparons différentes approches dans ce travail, à savoir, des modèles de langue utilisant des unités différentes pour l'apprentissage non supervisé et pour le décodage (des caractères et des mots avec des vocabulaires de différentes tailles), l'utilisation de phonèmes et d'unités ``demi-syllabiques'' et deux approches différentes d'apprentissage non supervisé.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j3']);">.bib</a> [Laurent14j3] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j3.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j3']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j2_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j2']);">
        Analyse du corpus MATRICE : exploration et classification automatique d'archives audiovisuelles de 1930 à 2012
        </a>
    </div>
    <div id="collapseLaurent14j2_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Guinaudeau, C., Roy, A.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Cet article décrit les méthodes mises en place pour permettre l'analyse d'un corpus composé de documents audiovisuels diffusés au cours des 80 dernières années : le corpus MATRICE. Nous proposons une exploration des données permettant de mettre en évidence les différents thèmes et évènements abordés dans le corpus. Cette exploration est, dans un premier temps, effectuée sur des notices documentaires produites manuellement par les documentalistes de l'Institut National de l'Audiovisuel. Puis, nous montrons, grâce à une étude qualitative et une technique de clustering automatique, que les transcriptions automatiques permettent également d'effectuer une analyse du corpus faisant émerger des thèmes cohérents avec les données traitées.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j2']);">.bib</a> [Laurent14j2] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j2.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j2']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent14j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent14j1']);">
        Boosting de bonzaï pour la combinaison efficace de descripteurs : application à l'identification du rôle du locuteur
        </a>
    </div>
    <div id="collapseLaurent14j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Camelin, N., Raymond, C.
<p><em>JEP 2014, Journées d'Etudes sur la Parole</em></p>
<blockquote><p>Dans ce travail, nous nous intéressons au problème de la détection du rôle du locuteur dans les émissions d'actualités radiotélévisées. Dans la littérature, les solutions proposées sont de combiner des indicateurs variés provenant de l'acoustique, de la transcription et/ou de son analyse par des méthodes d'apprentissage automatique. De nombreuses études font ressortir l'algorithme de boosting sur des règles de décision simples comme l'un des plus efficaces à combiner ces différents descripteurs. Nous proposons ici une modification de cet algorithme état-de-l'art en remplaçant ces règles de décision simples par des mini arbres de décision que nous appelons bonzaïs. Les expériences comparatives menées sur le corpus EPAC montrent que cette modification améliore largement les performances du système tout en réduisant le temps d'apprentissage de manière conséquente.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent14j1']);">.bib</a> [Laurent14j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent14j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent14j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseguinaudeau14_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'guinaudeau14']);">
        LIMSI @ MediaEval SED 2014
        </a>
    </div>
    <div id="collapseguinaudeau14_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Guinaudeau, C., Laurent, A., Bredin, H.
<p><em>MediaEval 2014 Social Event Detection Task. Working Notes Proceedings</em></p>
<blockquote><p>This paper provides an overview of the Social Event Detection (SED) system developed at LIMSI for the 2014 campaign. Our approach is based on a hierarchical agglomerative clustering that uses textual metadata, user-based knowledge and geographical information. These different sources of knowledge, either used separately or in cascade, reach good results for the full clustering subtask with a normalized mutual information equal to 0.95 and F1 scores greater than 0.82 for our best run.</p></blockquote>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'guinaudeau14']);">.bib</a> [guinaudeau14] | <i class="icon-book"></i> <a href="/download/pdfs/guinaudeau14.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'guinaudeau14']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent12_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12']);">
        Combining transcription-based and acoustic-based speaker identifications for broadcast news
        </a>
    </div>
    <div id="collapseLaurent12_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        El-Khoury, E., Laurent, A., Meignier, S., Petitrenaud, S.
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12']);">.bib</a> [Laurent12] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent12j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent12j1']);">
        Combinaison d'approches pour la reconnaissance du rôle des locuteurs
        </a>
    </div>
    <div id="collapseLaurent12j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Dufour, R., Laurent, A., Estève, Y.
<p><em>JEP 2012, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent12j1']);">.bib</a> [Laurent12j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent12j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent12j1']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent11_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent11']);">
        Computer-assisted transcription of speech based on confusion network reordering
        </a>
    </div>
    <div id="collapseLaurent11_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>ICASSP 2011, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent11']);">.bib</a> [Laurent11] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent11.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent11']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseEstève10_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Estève10']);">
        Some recent research work at LIUM based on the use of CMU Sphinx
        </a>
    </div>
    <div id="collapseEstève10_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Estève, Y., Deléglise, P., Meignier, S., Petitrenaud, S., Schwenk, H., Barrault, L., Bougares, F., Dufour, R., Jousse, V., Laurent, A., Rousseau, A.
<p><em>Workshop CMU SPU</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Estève10']);">.bib</a> [Estève10] |         </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent10j1_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10j1']);">
        Réordonnancement automatique d'hypothèses pour l'assistance à la transcription de la parole
        </a>
    </div>
    <div id="collapseLaurent10j1_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A.,  Meignier, S., Deléglise, P.
<p><em>JEP 2010, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10j1']);">.bib</a> [Laurent10j1] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10j1.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10j1']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent10-b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent10-b']);">
        Acoustics-Based Phonetic Transcription Method for Proper Nouns
        </a>
    </div>
    <div id="collapseLaurent10-b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Meignier, S., Merlin, T., Deléglise, P.
<p><em>Interspeech 2010, 11th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent10-b']);">.bib</a> [Laurent10-b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent10-b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent10-b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent09b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09b']);">
        Grapheme to phoneme conversion using an SMT system
        </a>
    </div>
    <div id="collapseLaurent09b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Deléglise, P., Meignier, S.
<p><em>Interspeech 2009, 10th Annual Conference of the International Speech Communication Association</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09b']);">.bib</a> [Laurent09b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent09_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent09']);">
        Iterative filtrering of phonetic transcriptions of proper nouns
        </a>
    </div>
    <div id="collapseLaurent09_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>ICASSP 2009, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent09']);">.bib</a> [Laurent09] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent09.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent09']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent08b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08b']);">
        Combinaison de systèmes pour la phonétisation automatique de noms propres
        </a>
    </div>
    <div id="collapseLaurent08b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., and Meignier, S., Estève, Y., Deléglise, P.
<p><em>JEP 2008, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08b']);">.bib</a> [Laurent08b] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLaurent08_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Laurent08']);">
        Combined systems for automatic phonetic transcription of proper nouns
        </a>
    </div>
    <div id="collapseLaurent08_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Laurent, A., Merlin, T., Meignier, S., Estève, Y., Deléglise, P.
<p><em>LREC 2008, Language Resources and Evaluation Conference</em></p>
<i class="icon-tags"></i> <a href="/laurent.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Laurent08']);">.bib</a> [Laurent08] | <i class="icon-book"></i> <a href="/download/pdfs/Laurent08.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Laurent08']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-51856344-1', 'antoine-laurent.fr');
  ga('send', 'pageview');

</script>
